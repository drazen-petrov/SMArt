{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbccb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\draze\\poso_local\\coding\\clean_smart\\GROMOS_GIT\\SMArt\\SMArt\\local_config\\__init__.py:22: WARN: gmx not found\n",
      "  do_warn('gmx not found')\n",
      "C:\\Users\\draze\\poso_local\\coding\\clean_smart\\GROMOS_GIT\\SMArt\\SMArt\\local_config\\__init__.py:34: WARN: gpp not found\n",
      "  do_warn('gpp not found')\n",
      "C:\\Users\\draze\\poso_local\\coding\\clean_smart\\GROMOS_GIT\\SMArt\\SMArt\\local_config\\__init__.py:42: WARN: gxx not found\n",
      "  do_warn('gxx not found')\n",
      "C:\\Users\\draze\\poso_local\\coding\\clean_smart\\GROMOS_GIT\\SMArt\\SMArt\\local_config\\__init__.py:50: WARN: pdb2pqr not found\n",
      "  do_warn('pdb2pqr not found')\n"
     ]
    }
   ],
   "source": [
    "# importing and preparing some variables\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "\n",
    "smart_fd = os.path.abspath(os.getcwd())\n",
    "for _ in range(3):\n",
    "    smart_fd = os.path.split(smart_fd)[0]\n",
    "\n",
    "\n",
    "sys.path.insert(0, smart_fd)\n",
    "\n",
    "import SMArt\n",
    "SMArt.incl.set_print_warnings(0)\n",
    "from SMArt.md import parse_top\n",
    "\n",
    "\n",
    "out_fd = os.path.abspath(os.getcwd())\n",
    "out_fd = os.path.join(out_fd, 'out_data')\n",
    "if not os.path.isdir(out_fd):\n",
    "    os.mkdir(out_fd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d735109c",
   "metadata": {},
   "source": [
    "## Perturbation topologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2a1250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SMArt import alchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdf34469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            top        \n",
       "              0       1\n",
       "atom 0    3 ON2   3 ON2\n",
       "     1    2 CN1   2 CN1\n",
       "     2      4 N     4 N\n",
       "     3     6 CA    6 CA\n",
       "     4     7 CB    7 CB\n",
       "     5     8 CG    8 CG\n",
       "     6     9 CD    9 CD\n",
       "     7     15 C    15 C\n",
       "     8    10 CE   10 CE\n",
       "     9    11 NZ   11 NZ\n",
       "     10  17 NTE  17 NTE\n",
       "     11   1 CN2   1 CN2\n",
       "     12     5 H     5 H\n",
       "     13    16 O    16 O\n",
       "     14  13 HZ2     DUM\n",
       "     15  14 HZ3     DUM\n",
       "     16  12 HZ1     DUM\n",
       "     17   18 H1   18 H1\n",
       "     18   19 H2   19 H2\n",
       "     19     DUM  14 CH3\n",
       "     20     DUM  12 CH1\n",
       "     21     DUM  13 CH2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GROMACS\n",
    "top_wt_file = os.path.join(smart_fd, 'doc', 'examples', 'some_data', 'gromacs', 'LYSH.top')\n",
    "top_wt = parse_top(top_wt_file, format_type='gm')\n",
    "top_PTM_file = os.path.join(smart_fd, 'doc', 'examples', 'some_data', 'gromacs', 'K3C.top')\n",
    "top_PTM = parse_top(top_PTM_file, format_type='gm')\n",
    "mt_wt, mt_PTP = top_wt.molecule_types['mol_1'], top_PTM.molecule_types['mol_1']\n",
    "\n",
    "sol = alchemy.point_mutation(mt_wt, mt_PTP, ff_dumm = top_wt.get_DUM_type) # flag_top_prune = 'bond' (by default)\n",
    "out_itp = os.path.join(out_fd, 'toptp.itp')\n",
    "sol.toptp.write_itp(out_itp, flag_generate_excl_pairs = True)\n",
    "sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "287780b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            top        \n",
       "              0       1\n",
       "atom 0    3 ON2   3 ON2\n",
       "     1    2 CN1   2 CN1\n",
       "     2      4 N     4 N\n",
       "     3     6 CA    6 CA\n",
       "     4     7 CB    7 CB\n",
       "     5     8 CG    8 CG\n",
       "     6     9 CD    9 CD\n",
       "     7     15 C    15 C\n",
       "     8    10 CE   10 CE\n",
       "     9    11 NZ   11 NZ\n",
       "     10  17 NTE  17 NTE\n",
       "     11   1 CN2   1 CN2\n",
       "     12     5 H     5 H\n",
       "     13    16 O    16 O\n",
       "     14  14 HZ3     DUM\n",
       "     15  13 HZ2     DUM\n",
       "     16  12 HZ1     DUM\n",
       "     17   18 H1   18 H1\n",
       "     18   19 H2   19 H2\n",
       "     19     DUM  12 CH1\n",
       "     20     DUM  14 CH3\n",
       "     21     DUM  13 CH2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GROMOS\n",
    "top_wt_file = os.path.join(smart_fd, 'doc', 'examples', 'some_data', 'gromos', 'LYSH.top')\n",
    "top_wt = parse_top(top_wt_file)\n",
    "top_PTM_file = os.path.join(smart_fd, 'doc', 'examples', 'some_data', 'gromos', 'K3C.top')\n",
    "top_PTM = parse_top(top_PTM_file)\n",
    "\n",
    "sol = alchemy.point_mutation(top_wt, top_PTM) # flag_top_prune = 'bond' (by default)\n",
    "sol.toptp.write_top(os.path.join(out_fd, 'toptp.top'))\n",
    "sol.toptp.write_ptp(os.path.join(out_fd, 'toptp.ptp'))\n",
    "sol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75d6545",
   "metadata": {},
   "source": [
    "## EDS topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ce8967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            top                        \n",
       "              0       1       2       3\n",
       "atom 0     5 C6    5 C6    5 C6    5 C6\n",
       "     1     7 C8    7 C8    7 C8    7 C8\n",
       "     2     1 C1    1 C1    1 C1    1 C1\n",
       "     3    9 C10   9 C10   9 C10   9 C10\n",
       "     4   20 C25  20 C25  20 C25  20 C25\n",
       "     5     3 C4    3 C4    3 C4    3 C4\n",
       "     6   10 N11  10 N11  10 N11  10 N11\n",
       "     7   12 C13  12 C13  12 C13  12 C13\n",
       "     8   15 N20  15 N20  15 N20  15 N20\n",
       "     9   17 S22  17 S22  17 S22  17 S22\n",
       "     10  11 C12  11 C12  11 C12  11 C12\n",
       "     11  14 C19  14 C19  14 C19  13 C14\n",
       "     12    6 H7    6 H7    6 H7     DUM\n",
       "     13    8 H9    8 H9    8 H9    8 H9\n",
       "     14    2 H2     DUM    2 H2    2 H2\n",
       "     15    4 H5    4 H5     DUM    4 H5\n",
       "     16  16 H21  16 H21  16 H21  16 H21\n",
       "     17  19 O24  19 O24  18 O23  19 O24\n",
       "     18  18 O23  18 O23  19 O24  18 O23\n",
       "     19  13 C14  13 C14  13 C14  14 C19\n",
       "     20     DUM    2 F2     DUM     DUM\n",
       "     21     DUM     DUM    4 F5     DUM\n",
       "     22     DUM     DUM     DUM    6 F7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOPs_path = os.path.join(smart_fd, 'doc', 'examples', 'some_data', 'gromos', 'GRA2', 'tops', '*top')\n",
    "TOPs = glob.glob(TOPs_path)\n",
    "\n",
    "tops = [parse_top(fpath) for fpath in TOPs]\n",
    "sol_EDS, state_names = alchemy.get_EDS(*tops[:4]) # first 4 tops; faster than all 16 topologies (line below)\n",
    "#sol_EDS, state_names = alchemy.get_EDS(*tops)\n",
    "\n",
    "sol_EDS.toptp.write_top(os.path.join(out_fd, 'EDS.top'))\n",
    "sol_EDS.toptp.write_EDS(os.path.join(out_fd, 'EDS.ptp'), state_names=state_names)\n",
    "sol_EDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e866b164",
   "metadata": {},
   "source": [
    "## Simulation update (perturbation free energy calculations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6efd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing\n",
    "from SMArt.md.ana import pert_FE\n",
    "\n",
    "from SMArt.md.gromos.io.ana import read_bar_dhdl, read_exTI\n",
    "from SMArt.md.gromacs.io.ana import read_bar_data, read_xvg_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd5a4b6",
   "metadata": {},
   "source": [
    "#### download required data\n",
    "to run the following code, first download (and unpack into \"FE_data\" directory) the example perturbation free energy data from:<br>\n",
    "DOI: 10.5281/zenodo.4682224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f84ef39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tREADING...\n",
      "\tDONE READING\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# reding raw data - outout from gromacs simulations\n",
    "fd_data = os.path.join(smart_fd, 'doc', 'examples', 'some_data', 'FE_data', 'GROMACS_PHD_K4me')\n",
    "Fs_bar = glob.glob(os.path.join(fd_data, '*', '*', '*FE_md_*xvg'))\n",
    "\n",
    "LPs_iter = {}\n",
    "dl = 0.1\n",
    "LPs_all = set()\n",
    "for i in range(3):\n",
    "        LPs_iter[i] = set(pert_FE.get_lset(np.arange(0, 1.001, dl))) - LPs_all\n",
    "        LPs_all |= LPs_iter[i]\n",
    "        dl *= 0.5\n",
    "\n",
    "\n",
    "max_l = 0.3\n",
    "\n",
    "print('\\tREADING...')\n",
    "raw_bar_data_iter = {}\n",
    "for f in Fs_bar:\n",
    "        data, sim_l = read_bar_data(f, dl_max = max_l)\n",
    "        sim_iter = 0\n",
    "        sim_iter +=int(re.search('md_(\\d*)', f).group(1))\n",
    "        for i in range(3):\n",
    "                if sim_l in LPs_iter[i]:\n",
    "                        sim_iter += i\n",
    "        sim_index = f\n",
    "        for i in range(2):sim_index = os.path.split(sim_index)[0]\n",
    "        sim_index = int(os.path.split(sim_index)[1]) - 1\n",
    "        #if sim_l in (0., 0.025, 0.05):print(sim_l, os.path.split(f)[1], sim_iter, sim_index)\n",
    "        if sim_iter not in raw_bar_data_iter:\n",
    "                raw_bar_data_iter[sim_iter] = {}\n",
    "        if sim_index not in raw_bar_data_iter[sim_iter]:\n",
    "                raw_bar_data_iter[sim_iter][sim_index] = []\n",
    "        raw_bar_data_iter[sim_iter][sim_index].append((data, sim_l))\n",
    "\n",
    "print('\\tDONE READING')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf4bb1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\tITER  0\n",
      "simulated data: {0.0: 1.0, 0.1: 1.0, 0.2: 1.0, 0.3: 1.0, 0.4: 1.0, 0.5: 1.0, 0.6: 1.0, 0.7: 1.0, 0.8: 1.0, 0.9: 1.0, 1.0: 1.0}\n",
      "converged_segments: [(0.1, 0.3), (0.5, 1.0)]\n",
      "new lambda points - weights: {0.0: 0.13, 0.05: 0.21, 0.1: 0.08, 0.3: 0.08, 0.35: 0.16, 0.4: 0.14, 0.45: 0.13, 0.5: 0.06}\n",
      "new lambda points - times: {0.0: 1.0, 0.05: 1.0, 0.1: 1.0, 0.3: 1.0, 0.35: 1.0, 0.4: 1.0, 0.45: 1.0, 0.5: 1.0}\n",
      "\n",
      "\tITER  1\n",
      "simulated data: {0.0: 2.0, 0.1: 2.0, 0.2: 1.0, 0.3: 2.0, 0.4: 2.0, 0.5: 2.0, 0.6: 1.0, 0.7: 1.0, 0.8: 1.0, 0.9: 1.0, 1.0: 1.0, 0.05: 1.0, 0.35: 1.0, 0.45: 1.0}\n",
      "converged_segments: [(0.025, 1.0)]\n",
      "new lambda points - weights: {0.0: 0.5, 0.025: 0.5}\n",
      "new lambda points - times: {0.0: 1.0, 0.025: 1.0}\n",
      "\n",
      "\tITER  2\n",
      "simulated data: {0.0: 3.0, 0.1: 2.0, 0.2: 1.0, 0.3: 2.0, 0.4: 2.0, 0.5: 2.0, 0.6: 1.0, 0.7: 1.0, 0.8: 1.0, 0.9: 1.0, 1.0: 1.0, 0.05: 1.0, 0.35: 1.0, 0.45: 1.0, 0.025: 1.0}\n",
      "converged_segments: [(0.025, 1.0)]\n",
      "new lambda points - weights: {0.0: 0.5, 0.025: 0.5}\n",
      "new lambda points - times: {0.0: 1.0, 0.025: 1.0}\n",
      "\n",
      "\tITER  3\n",
      "simulated data: {0.0: 4.0, 0.1: 2.0, 0.2: 1.0, 0.3: 2.0, 0.4: 2.0, 0.5: 2.0, 0.6: 1.0, 0.7: 1.0, 0.8: 1.0, 0.9: 1.0, 1.0: 1.0, 0.05: 1.0, 0.35: 1.0, 0.45: 1.0, 0.025: 2.0}\n",
      "converged_segments: [(0.025, 1.0)]\n",
      "new lambda points - weights: {0.0: 0.5, 0.025: 0.5}\n",
      "new lambda points - times: {0.0: 1.0, 0.025: 1.0}\n",
      "\n",
      "\tITER  4\n",
      "simulated data: {0.0: 5.0, 0.1: 2.0, 0.2: 1.0, 0.3: 2.0, 0.4: 2.0, 0.5: 2.0, 0.6: 1.0, 0.7: 1.0, 0.8: 1.0, 0.9: 1.0, 1.0: 1.0, 0.05: 1.0, 0.35: 1.0, 0.45: 1.0, 0.025: 3.0}\n",
      "converged_segments: [(0.0, 1.0)]\n",
      "new lambda points - weights: {}\n",
      "new lambda points - times: {}\n"
     ]
    }
   ],
   "source": [
    "# update scheme:\n",
    "    # dG_MBAR_err < kT\n",
    "    # dG_MBAR_half_fw < kT\n",
    "    # dG_MBAR_half_bw < kT\n",
    "    # OI > 0.5\n",
    "\n",
    "pert_FE.dG_err_tols._dG_err_tols__BS_steps = 0 # turns off bootstrapping\n",
    "pert_FE.dG_err_tols._dG_err_tols__OI_tol = 0.5 # setting overlap integral tolerance to 0.5\n",
    "\n",
    "bar_data = {}\n",
    "converged_segments = []\n",
    "for i in sorted(raw_bar_data_iter):\n",
    "    print('\\n\\tITER ', i)\n",
    "    temp_LPs_iter_set = set()\n",
    "    for sim_index in raw_bar_data_iter[i]:\n",
    "        for data, sim_l in raw_bar_data_iter[i][sim_index]:\n",
    "            pert_FE.combine_bar_dhdl(bar_data, data, sim_l, append_index=sim_index)\n",
    "            temp_LPs_iter_set.add(sim_l)\n",
    "    if i==0:\n",
    "            LPs_times = dict((temp_lp, 1.) for temp_lp in bar_data)\n",
    "    print('simulated data:', LPs_times)\n",
    "    seg_score_flag, converged_segments, new_LPs_weights, seg_data_dG_err = pert_FE.update_LPs_times(bar_data, ncpu=8, converged_segments=converged_segments)\n",
    "    print('converged_segments:', converged_segments)\n",
    "    for l in new_LPs_weights:\n",
    "        new_LPs_weights[l] = round(new_LPs_weights[l], 2)\n",
    "    print('new lambda points - weights:', new_LPs_weights)\n",
    "    new_LPs_times = pert_FE.get_LPs_times(new_LPs_weights, LPs_times, 11.)\n",
    "    print('new lambda points - times:', new_LPs_times)\n",
    "    #if i==0:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8d404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
